# Data-pipeline-using-Airflow-and-Snowflake
 

## Objective

This project aims to orchestrate a data pipleine using SNowflake operators in Airflow. This involves setting up the integration between airflow and Snowflake as well as an end-to-end automated workflow that includes data ingestion, transformation, analytics, and consumption.

## Technologies

- Language: Python, SQL
- Tools: Amazon MWAA(Airflow), Snowflake, Amazon SNS, AWS S3, AWS Secrets Manager, IAM


## Dataset

The publiclly available data is extracted from [S3 bucket](https://citibikenyc.com/system-data) and saved locally. Further explanation of the variables and features used can be found here.

